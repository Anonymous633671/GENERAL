{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import sys\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from operator import add \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from collections import Counter\n",
    "\n",
    "from utils import *\n",
    "import CFS\n",
    "\n",
    "import TCA\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(project, metric):\n",
    "    data_path = '../data/700/merged_data_original/' + project + '.csv'\n",
    "    data_df = pd.read_csv(data_path)\n",
    "    data_df.rename(columns = {'Unnamed: 0':'id'},inplace = True)\n",
    "\n",
    "    for col in ['id', 'commit_hash', 'release']:\n",
    "        if col in data_df.columns:\n",
    "            data_df = data_df.drop([col], axis = 1)\n",
    "    data_df = data_df.dropna()\n",
    "    y = data_df.Bugs\n",
    "    X = data_df.drop(['Bugs'],axis = 1)\n",
    "    if metric == 'process':\n",
    "        X = X[['file_la', 'file_ld', 'file_lt', 'file_age', 'file_ddev',\n",
    "    'file_nuc', 'own', 'minor', 'file_ndev', 'file_ncomm', 'file_adev',\n",
    "    'file_nadev', 'file_avg_nddev', 'file_avg_nadev', 'file_avg_ncomm',\n",
    "    'file_ns', 'file_exp', 'file_sexp', 'file_rexp', 'file_nd', 'file_sctr']]\n",
    "    elif metric == 'product':\n",
    "        X = X.drop(['file_la', 'file_ld', 'file_lt', 'file_age', 'file_ddev',\n",
    "    'file_nuc', 'own', 'minor', 'file_ndev', 'file_ncomm', 'file_adev',\n",
    "    'file_nadev', 'file_avg_nddev', 'file_avg_nadev', 'file_avg_ncomm',\n",
    "    'file_ns', 'file_exp', 'file_sexp', 'file_rexp', 'file_nd', 'file_sctr'],axis = 1)\n",
    "    else:\n",
    "        X = X\n",
    "    df = X\n",
    "    df['Bugs'] = y\n",
    "    return df\n",
    "\n",
    "def apply_cfs(df):\n",
    "    y = df.Bugs.values\n",
    "    X = df.drop(labels = ['Bugs'],axis = 1)\n",
    "    X = X.values\n",
    "    selected_cols = CFS.cfs(X,y)\n",
    "    cols = df.columns[[selected_cols]].tolist()\n",
    "    cols.append('Bugs')\n",
    "    return df[cols],cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame()\n",
    "metric = 'process'\n",
    "all_imp = {}\n",
    "for i in range(1):\n",
    "    _imp = {}\n",
    "    fold = str(i)\n",
    "    data_location = 'results/median_data/level_2/fold_' + fold\n",
    "    bell_df = pd.read_csv(data_location + '/bellwether_cdom_0.csv')\n",
    "    bellwether = bell_df.bellwether.values.tolist()[0]\n",
    "    df = prepare_data(bellwether, metric)\n",
    "    all_cols = df.columns\n",
    "    new_df, cols = apply_cfs(df)\n",
    "    y = new_df.Bugs\n",
    "    X = new_df.drop(labels = ['Bugs'],axis = 1)\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X,y)\n",
    "    imp = clf.feature_importances_\n",
    "    for col in all_cols:\n",
    "        _imp[col] = 0.0\n",
    "    for j in range(len(cols)-1):\n",
    "        col = cols[j]\n",
    "        _imp[col] = imp[j]\n",
    "    all_imp[i] = _imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imp_df = pd.DataFrame.from_dict(all_imp, orient = 'index')\n",
    "all_imp_df = round(all_imp_df.sum(), 2)\n",
    "all_imp_df.to_csv('results/median_data/features/features_01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = pd.read_pickle('results/attributes/projects_attributes.pkl')\n",
    "attributes_df = pd.DataFrame.from_dict(attributes, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'gradle-retrolambda'\n",
      "'the-app'\n",
      "'derive4j'\n",
      "'jetcache'\n"
     ]
    }
   ],
   "source": [
    "feature_imp = pd.DataFrame()\n",
    "metric = 'process'\n",
    "all_imp = {}\n",
    "for i in range(1):\n",
    "    fold = str(i)\n",
    "    data_location = 'results/median_data/level_2/fold_' + fold\n",
    "    bell_df = pd.read_csv(data_location + '/bellwether_cdom_2.csv')\n",
    "    for cluster in bell_df.id.values.tolist():\n",
    "        cdom_df = pd.read_csv(data_location + '/' + str(cluster) + '/cdom_latest.csv', index_col = 0)\n",
    "        projects = cdom_df.index.values.tolist()\n",
    "        for project in projects:\n",
    "            try:\n",
    "                df = prepare_data(project, metric)\n",
    "                _imp = {}\n",
    "                all_cols = df.columns\n",
    "                for col in all_cols:\n",
    "                    _imp[col] = 0.0\n",
    "                s_cols = []\n",
    "                for j  in range(attributes_df.loc[project].shape[0]):\n",
    "                    col = attributes_df.loc[project].values.tolist()[j]\n",
    "                    if col == 1:\n",
    "                        s_cols.append(all_cols[j])\n",
    "                new_df = df[s_cols]\n",
    "                y = new_df.Bugs\n",
    "                X = new_df.drop(labels = ['Bugs'],axis = 1)\n",
    "                clf = RandomForestClassifier()\n",
    "                clf.fit(X,y)\n",
    "                imp = clf.feature_importances_\n",
    "                for k in range(len(s_cols)-1):\n",
    "                    col = s_cols[k]\n",
    "                    _imp[col] = round(imp[k],2)\n",
    "                all_imp[project] = _imp\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imp_df = pd.DataFrame.from_dict(all_imp, orient = 'index')\n",
    "all_imp_df = round(all_imp_df.sum()/all_imp_df.shape[0],2)\n",
    "all_imp_df.to_csv('results/median_data/features/features_all_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
